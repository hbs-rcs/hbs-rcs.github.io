<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R | HBS Research Computing Services Blog</title>
    <link>https://hbs-rcs.github.io/tag/r/</link>
      <atom:link href="https://hbs-rcs.github.io/tag/r/index.xml" rel="self" type="application/rss+xml" />
    <description>R</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 10 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://hbs-rcs.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>R</title>
      <link>https://hbs-rcs.github.io/tag/r/</link>
    </image>
    
    <item>
      <title>Easier web scraping in R with tidyverse</title>
      <link>https://hbs-rcs.github.io/post/easier-web-scraping-in-r-with-tidyverse/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hbs-rcs.github.io/post/easier-web-scraping-in-r-with-tidyverse/</guid>
      <description>


&lt;p&gt;I recently used R for a moderately complicated scraping task, and found that using
tools and techniques from the &lt;em&gt;tidyverse&lt;/em&gt; made for a very pleasant web scraping
experience, especially for retrieving nested data. In particular, the &lt;em&gt;nest/unnest&lt;/em&gt;
functions in the &lt;code&gt;tidyr&lt;/code&gt; package make it easy to implement breadth-first scrapers in R by
nesting the results from each level and then expanding to a tabular structure. This
approach has the advantage of making it easy to follow the program logic, and it also
makes it very easy to store retrieved values in a convenient format.&lt;/p&gt;
&lt;div id=&#34;example-hbs-workshops&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example: HBS workshops&lt;/h2&gt;
&lt;p&gt;As a simple example of a website with a nested structure consider &lt;a href=&#34;https://training.rcs.hbs.org/workshops&#34; class=&#34;uri&#34;&gt;https://training.rcs.hbs.org/workshops&lt;/a&gt;.
This site lists workshops nested within categories.&lt;/p&gt;
&lt;div id=&#34;start-at-the-top-and-store-results-in-tibbles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Start at the top and store results in tibbles&lt;/h3&gt;
&lt;p&gt;Using the &lt;em&gt;tidyverse&lt;/em&gt; packages along with &lt;em&gt;rvest&lt;/em&gt; make web scraping in R more convenient.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rvest)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To retrieve workshop information from &lt;a href=&#34;https://training.rcs.hbs.org&#34; class=&#34;uri&#34;&gt;https://training.rcs.hbs.org&lt;/a&gt; we can start by creating
a &lt;code&gt;tibble&lt;/code&gt; to store the data we will retrieve from the site. To begin with this &lt;code&gt;tibble&lt;/code&gt; has
only one row and one column containing the URL of the starting page. This might seem like
a strange way to start, but it helps us keep a consistent and clean pattern as we descend
through the nested structure of the website.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ws_data &amp;lt;- tibble(start_url = &amp;quot;https://training.rcs.hbs.org/workshops&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;store-retrieved-data-in-list-columns-and-unnest-as-needed&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Store retrieved data in list columns and unnest as needed&lt;/h3&gt;
&lt;p&gt;Next we &lt;em&gt;mutate&lt;/em&gt; the data, reading the page containing the outer-most collection
and extracting the information we need. The information we extract includes URLs
at the next level of the tree we are traversing. Because we will retrieve multiple
elements we store the result in a list-column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ws_data &amp;lt;- ws_data %&amp;gt;%
  mutate(category = map(start_url,
                        ~ read_html(.) %&amp;gt;%
                          html_nodes(&amp;quot;.menu-depth-2 a&amp;quot;) %&amp;gt;%
                          {tibble(name = html_text(.),
                                  url = html_attr(., &amp;quot;href&amp;quot;))})
  )

glimpse(ws_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 1
## Variables: 2
## $ start_url &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/workshops&amp;quot;
## $ category  &amp;lt;list&amp;gt; [&amp;lt;tbl_df[7 x 2]&amp;gt;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our data structure still only has one row, but we can easily expand it so that it has
one row per category.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ws_data &amp;lt;- ws_data %&amp;gt;%
  unnest(category, names_sep = &amp;quot;_&amp;quot;, keep_empty = TRUE)

glimpse(ws_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 7
## Variables: 3
## $ start_url     &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/workshops&amp;quot;, &amp;quot;https://tr...
## $ category_name &amp;lt;chr&amp;gt; &amp;quot;HBS Grid Training &amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;Stata&amp;quot;, &amp;quot;Python&amp;quot;, &amp;quot;Other ...
## $ category_url  &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/compute-grid-training&amp;quot;,...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each of the categories contains one or more workshops, so the next step is to iterate
over categories and retrieve the all the workshop links. Because we want to retrieve
more than one value for each category we store the result in a list-column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ws_data &amp;lt;- ws_data %&amp;gt;%
  mutate(workshop = map(category_url,
                        ~ read_html(.) %&amp;gt;%
                          html_nodes(&amp;quot;.menu-depth-3 a&amp;quot;) %&amp;gt;%
                          {tibble(name = html_text(.),
                                  url = html_attr(., &amp;quot;href&amp;quot;))})
  )

glimpse(ws_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 7
## Variables: 4
## $ start_url     &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/workshops&amp;quot;, &amp;quot;https://tr...
## $ category_name &amp;lt;chr&amp;gt; &amp;quot;HBS Grid Training &amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;Stata&amp;quot;, &amp;quot;Python&amp;quot;, &amp;quot;Other ...
## $ category_url  &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/compute-grid-training&amp;quot;,...
## $ workshop      &amp;lt;list&amp;gt; [&amp;lt;tbl_df[0 x 2]&amp;gt;, &amp;lt;tbl_df[5 x 2]&amp;gt;, &amp;lt;tbl_df[2 x 2]&amp;gt;, ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As before we unnest the data, making sure to keep empty rows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ws_data &amp;lt;- ws_data %&amp;gt;%
  unnest(workshop, names_sep = &amp;quot;_&amp;quot;, keep_empty = TRUE)

glimpse(ws_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 18
## Variables: 5
## $ start_url     &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/workshops&amp;quot;, &amp;quot;https://tr...
## $ category_name &amp;lt;chr&amp;gt; &amp;quot;HBS Grid Training &amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;Stata...
## $ category_url  &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/compute-grid-training&amp;quot;,...
## $ workshop_name &amp;lt;chr&amp;gt; NA, &amp;quot;Introduction to R&amp;quot;, &amp;quot;Introduction to R Graphics ...
## $ workshop_url  &amp;lt;chr&amp;gt; NA, &amp;quot;https://training.rcs.hbs.org/introduction-r&amp;quot;, &amp;quot;h...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-it-all-together&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Putting it all together&lt;/h3&gt;
&lt;p&gt;As simple as it is, the code examples above can be simplified even further by modularizing
the data processing functions. Here is the whole simplified program for retrieving workshop
information, in less than 20 lines of code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rvest)

get_links &amp;lt;- function(url, css) {
  read_html(url) %&amp;gt;%
    html_nodes(css) %&amp;gt;%
    {tibble(name = html_text(.),
            url = html_attr(., &amp;quot;href&amp;quot;))}
}

ws_data &amp;lt;- tibble(start_url = &amp;quot;https://training.rcs.hbs.org/workshops&amp;quot;)

ws_data &amp;lt;- ws_data %&amp;gt;%
  mutate(category = map(start_url, get_links, css = &amp;quot;.menu-depth-2 a&amp;quot;)) %&amp;gt;%
  unnest(category, names_sep = &amp;quot;_&amp;quot;, keep_empty = TRUE) %&amp;gt;%
  mutate(workshop = map(category_url, get_links, css = &amp;quot;.menu-depth-3 a&amp;quot;)) %&amp;gt;%
  unnest(workshop, names_sep = &amp;quot;_&amp;quot;, keep_empty = TRUE)

glimpse(ws_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 18
## Variables: 5
## $ start_url     &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/workshops&amp;quot;, &amp;quot;https://tr...
## $ category_name &amp;lt;chr&amp;gt; &amp;quot;HBS Grid Training &amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;Stata...
## $ category_url  &amp;lt;chr&amp;gt; &amp;quot;https://training.rcs.hbs.org/compute-grid-training&amp;quot;,...
## $ workshop_name &amp;lt;chr&amp;gt; NA, &amp;quot;Introduction to R&amp;quot;, &amp;quot;Introduction to R Graphics ...
## $ workshop_url  &amp;lt;chr&amp;gt; NA, &amp;quot;https://training.rcs.hbs.org/introduction-r&amp;quot;, &amp;quot;h...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;The key pattern is &lt;code&gt;mutate&lt;/code&gt; to a list-column
containing &lt;code&gt;tibbles&lt;/code&gt; and then &lt;code&gt;unnest&lt;/code&gt; to maintain a tabular record of URLs and results at
each level. This expands the data structure as you descend
through each level, resulting in a nice clean tabular structure at the end. At each level
&lt;code&gt;unest(names_sep = &#34;_&#34;)&lt;/code&gt; produces a consistent naming scheme with minimal effort. Finally,
this pattern generalizes easily to cases where you wish to retrieve multiple pieces of
information at each level.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Web Scraping in R</title>
      <link>https://hbs-rcs.github.io/post/2019-08-08-web-scraping-in-r/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://hbs-rcs.github.io/post/2019-08-08-web-scraping-in-r/</guid>
      <description>


&lt;p&gt;Let’s walk through some steps for web scraping with R. On &lt;a href=&#34;https://en.wikipedia.org/wiki/Visa_requirements_for_United_States_citizens&#34;&gt;this Wikipedia page&lt;/a&gt; there is a table of visa requirements that I want to scrape. Let’s use the &lt;a href=&#34;https://github.com/hadley/rvest&#34;&gt;rvest&lt;/a&gt; package to get the HTML associated with that page:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)

html &amp;lt;- read_html(&amp;quot;https://en.wikipedia.org/wiki/Visa_requirements_for_United_States_citizens&amp;quot;)
html&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## {html_document}
## &amp;lt;html class=&amp;quot;client-nojs&amp;quot; lang=&amp;quot;en&amp;quot; dir=&amp;quot;ltr&amp;quot;&amp;gt;
## [1] &amp;lt;head&amp;gt;\n&amp;lt;meta http-equiv=&amp;quot;Content-Type&amp;quot; content=&amp;quot;text/html; charset= ...
## [2] &amp;lt;body class=&amp;quot;mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-sub ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s use the &lt;code&gt;html_nodes()&lt;/code&gt; function to extract the table of interest. I used Chrome’s Developer Tools to get the XPath of the table (see notes at the end of the post on how to do it):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;referenced_by &amp;lt;- html_node(html, xpath=&amp;#39;//*[@id=&amp;quot;mw-content-text&amp;quot;]/div/table[1]&amp;#39;)
referenced_by&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## {html_node}
## &amp;lt;table class=&amp;quot;sortable wikitable&amp;quot;&amp;gt;
## [1] &amp;lt;tbody&amp;gt;\n&amp;lt;tr&amp;gt;\n&amp;lt;th style=&amp;quot;width:18%;&amp;quot;&amp;gt;Country\n&amp;lt;/th&amp;gt;\n&amp;lt;th style=&amp;quot;wid ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s convert that HTML table into a data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;visa_requirements &amp;lt;- html_table(referenced_by)
head(visa_requirements[,1:3])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               Country          Visa requirement     Allowed stay
## 1         Afghanistan       Visa required[2][3]                 
## 2             Albania   Visa not required[5][6]        1 year[7]
## 3             Algeria       Visa required[8][9]                 
## 4             Andorra     Visa not required[10] 3 months[11][12]
## 5              Angola         eVisa[13][14][15]          30 days
## 6 Antigua and Barbuda Visa not required[18][19]     6 months[20]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can clean footnote references from columns 2 and 3 using &lt;code&gt;gsub()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;visa_requirements &amp;lt;- html_table(referenced_by)
visa_requirements$`Visa requirement` &amp;lt;- gsub(&amp;quot;\\[.*&amp;quot;,&amp;quot;&amp;quot;,visa_requirements$`Visa requirement`)
visa_requirements$`Allowed stay` &amp;lt;-  gsub(&amp;quot;\\[.*&amp;quot;,&amp;quot;&amp;quot;,visa_requirements$`Allowed stay`)
head(visa_requirements[,1:3])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               Country  Visa requirement Allowed stay
## 1         Afghanistan     Visa required             
## 2             Albania Visa not required       1 year
## 3             Algeria     Visa required             
## 4             Andorra Visa not required     3 months
## 5              Angola             eVisa      30 days
## 6 Antigua and Barbuda Visa not required     6 months&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve only scratched the surface here, but hope this example shows off the convenience of the &lt;code&gt;rvest&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Chrome’s Developer Tools can be launched by right-clicking on the page and selecting Inspect. Then, mouse over the html code listed under elements and find a place that highlights the table of interest on the right. Then right-click again, select Copy -&amp;gt; Copy XPath.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If writing custom scraping scripts in R is not the route you’d want to take, our team has recently discovered a very nice and flexible commercial tool &lt;a href=&#34;https://www.mozenda.com/&#34;&gt;Mozenda&lt;/a&gt;. As of 8/8/2019, they offer a 30-day trial of a full product.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Use machine learning for causal effect in observational study</title>
      <link>https://hbs-rcs.github.io/post/2017-03-01-causal_tmle/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://hbs-rcs.github.io/post/2017-03-01-causal_tmle/</guid>
      <description>


&lt;div id=&#34;a-simulation-for-ols-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A simulation for OLS model&lt;/h1&gt;
&lt;p&gt;In an observational study, we need to assume we have the functional form to get causal effect estimated correctly, in addtion to the assumption of treatment being exogenous.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(MASS)
library(ggplot2)
library(dplyr)
library(tmle)
library(glmnet)

set.seed(366)

nobs &amp;lt;- 2000
xw &amp;lt;- .8
xz &amp;lt;- .5
zw &amp;lt;- .6
nrow &amp;lt;- 3
ncol &amp;lt;- 3
covarMat = matrix( c(1^2, xz^2, xw^2, xz^2, 1^2, zw^2,  xw^2, zw^2, 1^2 ) , nrow=ncol , ncol=ncol )

mu &amp;lt;- rep(0,3)
rawvars &amp;lt;- mvrnorm(n=nobs, mu=mu, Sigma=covarMat)
df &amp;lt;- tbl_df(rawvars)
names(df) &amp;lt;- c(&amp;#39;x&amp;#39;,&amp;#39;z&amp;#39;,&amp;#39;w&amp;#39;)
df &amp;lt;- df %&amp;gt;%
    mutate(log.x=log(x^2), log.z=log(z^2), log.w=log(w^2), z.sqr=z^2, w.sqr=w^2) %&amp;gt;%
    mutate(g.var= log.w  + rnorm(nobs)) %&amp;gt;%
    mutate(A = rbinom(nobs, 1, 1/(1+exp((g.var))))) %&amp;gt;%
    mutate(y0=rnorm(nobs) + log.x) %&amp;gt;%
    mutate(tau.true = 2  + rnorm(nobs), y1=y0+tau.true, treat=A, y = treat*y1 + (1-treat)*y0)
lm1 &amp;lt;- lm(y ~ A + log.w + log.x , data=df)
summary(lm1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ A + log.w + log.x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5506 -0.8372 -0.0154  0.8502  4.1624 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.01267    0.04778   0.265    0.791    
## A            1.93171    0.06580  29.355   &amp;lt;2e-16 ***
## log.w        0.01105    0.01428   0.774    0.439    
## log.x        1.00162    0.01353  74.030   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.255 on 1996 degrees of freedom
## Multiple R-squared:  0.758,  Adjusted R-squared:  0.7576 
## F-statistic:  2084 on 3 and 1996 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm2 &amp;lt;- lm(y ~ A , data=df)
summary(lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ A, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.9102  -1.3822   0.3241   1.6933   6.4046 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -0.92139    0.08992  -10.25   &amp;lt;2e-16 ***
## A            1.38964    0.11366   12.23   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.459 on 1998 degrees of freedom
## Multiple R-squared:  0.06961,    Adjusted R-squared:  0.06915 
## F-statistic: 149.5 on 1 and 1998 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm3 &amp;lt;- lm(y ~ A + w, data=df)
summary(lm3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ A + w, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.9112  -1.3795   0.3139   1.6863   6.3468 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -0.92056    0.08995 -10.234   &amp;lt;2e-16 ***
## A            1.38860    0.11368  12.215   &amp;lt;2e-16 ***
## w           -0.03351    0.05286  -0.634    0.526    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.46 on 1997 degrees of freedom
## Multiple R-squared:  0.0698, Adjusted R-squared:  0.06887 
## F-statistic: 74.93 on 2 and 1997 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm4 &amp;lt;- lm(y ~ A + w + x, data=df)
summary(lm4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ A + w + x, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.9109  -1.4047   0.3177   1.6926   6.4528 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -0.91759    0.08995 -10.201   &amp;lt;2e-16 ***
## A            1.38335    0.11372  12.164   &amp;lt;2e-16 ***
## w           -0.09260    0.06827  -1.356    0.175    
## x            0.09947    0.07275   1.367    0.172    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.459 on 1996 degrees of freedom
## Multiple R-squared:  0.07067,    Adjusted R-squared:  0.06927 
## F-statistic:  50.6 on 3 and 1996 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, treatment assignment process is determined by logged w, and outcome is dtermined by logged x and treatment. However, what we observe is w and x. In observational studies, this happens all the time. In fact, this is an ideal situation, that we observe variables that are determinants of outcome, although we are not sure about the functional form that determines the outcome. However, this example shows that unless we have observed exactly the factors themselves (in this case logged x, w, which determines the DGP), we have biased estimates of the true treatment effect.&lt;/p&gt;
&lt;p&gt;Model 1 is the only model with reasonable estimate of treatment effect (which is 2 in this case). Model 2 is a model with endogeneity: A is correlated with the missing variabel logged x. Model 3 and 4 we have x and w, but not logged, therefore still biased.&lt;/p&gt;
&lt;p&gt;The lesson here is the functional form does matter. However, we have no way of knowing the functional form. What can we do here?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Q.SL.library &amp;lt;- c(&amp;quot;SL.randomForest&amp;quot;, &amp;quot;SL.glmnet&amp;quot;,&amp;quot;SL.loess&amp;quot;,&amp;quot;SL.glm&amp;quot;,&amp;quot;SL.glm.interaction&amp;quot;, &amp;quot;SL.rpart&amp;quot;,&amp;quot;SL.nnet&amp;quot;,&amp;quot;SL.bayesglm&amp;quot;,&amp;quot;SL.gam&amp;quot;,&amp;quot;SL.gbm&amp;quot;,&amp;quot;SL.step&amp;quot;,&amp;quot;SL.mean&amp;quot;)
g.SL.library &amp;lt;- c(&amp;quot;SL.randomForest&amp;quot;, &amp;quot;SL.glmnet&amp;quot;,&amp;quot;SL.glm&amp;quot;,&amp;quot;SL.glm.interaction&amp;quot;, &amp;quot;SL.rpart&amp;quot;,&amp;quot;SL.nnet&amp;quot;,&amp;quot;SL.bayesglm&amp;quot;,&amp;quot;SL.gam&amp;quot;,&amp;quot;SL.gbm&amp;quot;,&amp;quot;SL.step&amp;quot;,&amp;quot;SL.mean&amp;quot;)

# this one is good since both Q and g are correct (including z in it)
tmle1 &amp;lt;- tmle(Y = df$y, A = df$treat, W = df[,c(&amp;#39;x&amp;#39;,&amp;#39;w&amp;#39;)], g.SL.library = g.SL.library , Q.SL.library = Q.SL.library)
tmle1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Additive Effect
##    Parameter Estimate:  2.015
##    Estimated Variance:  0.0025985
##               p-value:  &amp;lt;2e-16
##     95% Conf Interval: (1.9151, 2.115)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tmle2 &amp;lt;- tmle(Y = df$y, A = df$treat, W = df[,c(&amp;#39;x&amp;#39;,&amp;#39;w&amp;#39;, &amp;#39;z&amp;#39;)], g.SL.library = g.SL.library , Q.SL.library = Q.SL.library)
tmle2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Additive Effect
##    Parameter Estimate:  2.0263
##    Estimated Variance:  0.0029254
##               p-value:  &amp;lt;2e-16
##     95% Conf Interval: (1.9202, 2.1323)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We use &lt;a href=&#34;http://biostats.bepress.com/ucbbiostat/paper275/&#34;&gt;Mark van der Laan’s TMLE method&lt;/a&gt;. It uses &lt;a href=&#34;http://biostats.bepress.com/ucbbiostat/paper222/&#34;&gt;SuperLearner&lt;/a&gt; as the initial estimator. It’s an ensemble of mulitple machine learning algorithms. Therefore it does not need to assume the functional form of the DGP. Even if we don’t have the variables that determines the DGP of outcome, if we observe some functions (even nonlinear functions) of these variables, we can still get reasonable estimates of the treatment effect.&lt;/p&gt;
&lt;p&gt;In this example, we used multiple popular machine learning algorithms in modeling both treatment assingment process and the outcome process. The first TMLE model is with x and w (note not the logged x and w which are in the true DGP), the second one with an additional variable z.&lt;/p&gt;
&lt;p&gt;It seems that TMLE results are less biased than the linear models with x and w. It may not be better than the linear model with logged x and w, but in empirical studies, we often cannot assume we have the variables in the DGP, but only some proxy of the variables in the DGP. I’ll do more simulations to see whether TMLE does perform better in the situation that we are not sure about the functional form. We should expect that is the case.&lt;/p&gt;
&lt;p&gt;So far TMLE can only be used when treatment is binary variable.&lt;/p&gt;
&lt;p&gt;It’s about time we embrace machine learning techniques into studies of caual effect in observational studies.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
